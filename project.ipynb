{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amadeus import Client, ResponseError\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "# Initialize Amadeus client\n",
    "amadeus = Client(client_id='JSLT2NK9MvK6L9gjhXxhv8oQbfSvGAy9', client_secret='hYE8hPobkZmyIFX5')\n",
    "\n",
    "\n",
    "'''\n",
    "List of origin and destination airport codes\n",
    "\n",
    "Rio (SDU) => Brasilia (BSB)\n",
    "Rio (SDU) => Congonhas (CGH)\n",
    "Rio (SDU) => Guarulhos (GRU)\n",
    "Congonhas (CGH) => Brasilia (BSB)\n",
    "Guarulhos (GRU) => Brasilia (BSB)\n",
    "Salvador (SAL) => Recife (REC)\n",
    "Salvador (SAL) => Brasilia (BSB)\n",
    "Recife (REC) => Brasilia (BSB)\n",
    "Recife (REC) => Curitiba (CWB)\n",
    "Curitiba (CWB) => Salvador (SAL)\n",
    "Curitiba (CWB) => Brasilia (BSB)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "origin_codes = ['SDU', 'CGH', 'GRU','SAL','REC','CWB']  # Add more origin codes as needed\n",
    "destination_codes = ['BSB', 'CGH', 'GRU','REC','SAL','CWB']  # Add more destination codes as needed\n",
    "\n",
    "# List of specific pairs of origin and destination\n",
    "specific_pairs = [('SDU', 'BSB'), ('SDU', 'CGH'), ('SDU', 'GRU'),('CGH', 'BSB'), ('GRU', 'BSB'), ('SAL', 'REC'),('SAL', 'BSB'), ('REC', 'BSB'), ('REC', 'CWB'),('CWB', 'SAL'), ('CWB', 'BSB')]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "flight_data = pd.DataFrame(columns=['FlightNumber', 'FlightDate', 'Origin', 'Destination', 'AirlineCode', 'Price', 'OrderID', 'Total Seats', 'Available Seats', 'Total Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flight_datas = pd.read_csv('data_2023-08-09_18-00-10.csv')\n",
    "#dfs = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traveler = {\n",
    "    'id': '1',\n",
    "    'dateOfBirth': '1982-01-16',\n",
    "    'name': {\n",
    "        'firstName': 'JORGE',\n",
    "        'lastName': 'GONZALES'\n",
    "    },\n",
    "    'gender': 'MALE',\n",
    "    'contact': {\n",
    "        'emailAddress': 'jorge.gonzales833@telefonica.es',\n",
    "        'phones': [{\n",
    "            'deviceType': 'MOBILE',\n",
    "            'countryCallingCode': '34',\n",
    "            'number': '480080076'\n",
    "        }]\n",
    "    },\n",
    "    'documents': [{\n",
    "        'documentType': 'PASSPORT',\n",
    "        'birthPlace': 'Madrid',\n",
    "        'issuanceLocation': 'Madrid',\n",
    "        'issuanceDate': '2015-04-14',\n",
    "        'number': '00000000',\n",
    "        'expiryDate': '2030-04-14',\n",
    "        'issuanceCountry': 'ES',\n",
    "        'validityCountry': 'ES',\n",
    "        'nationality': 'ES',\n",
    "        'holder': True\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=['Origin', 'Destination', 'Carrier Code', 'Flight Number', 'Total Bookable Seats'])\n",
    "\n",
    "# Set the search parameters and loop over specific pairs\n",
    "for origin, destination in specific_pairs:\n",
    "    body = {\n",
    "        \"originDestinations\": [\n",
    "            {\n",
    "                \"id\": \"1\",\n",
    "                \"originLocationCode\": origin,\n",
    "                \"destinationLocationCode\": destination,\n",
    "                \"departureDateTime\": {\n",
    "                    \"date\": date.today().isoformat()\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"travelers\": [\n",
    "            {\n",
    "                \"id\": \"1\",\n",
    "                \"travelerType\": \"ADULT\"\n",
    "            }\n",
    "        ],\n",
    "        \"sources\": [\n",
    "            \"GDS\"\n",
    "        ]\n",
    "    }\n",
    "    try:\n",
    "        response = amadeus.shopping.availability.flight_availabilities.post(body)\n",
    "\n",
    "        for entry in response.data:\n",
    "            segments = entry['segments']\n",
    "            for segment in segments:\n",
    "                total_bookable_seats = 0\n",
    "                for availability_class in segment['availabilityClasses']:\n",
    "                    total_bookable_seats += availability_class['numberOfBookableSeats']\n",
    "\n",
    "                segment_origin = segment['departure']['iataCode']\n",
    "                segment_destination = segment['arrival']['iataCode']\n",
    "                carrier_code = segment['carrierCode']\n",
    "                flight_number = segment['number']\n",
    "                \n",
    "                if (segment_origin, segment_destination) == (origin, destination):\n",
    "                    # Append data to the DataFrame\n",
    "                    df = df.append({'Origin': segment_origin, 'Destination': segment_destination, 'Carrier Code': carrier_code, 'Flight Number': flight_number, 'Total Bookable Seats': total_bookable_seats}, ignore_index=True)\n",
    "    except ResponseError as error:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the search parameters and loop over specific pairs\n",
    "for origin, destination in specific_pairs:\n",
    "    # Set the search parameters for each specific pair\n",
    "    search_params = {\n",
    "        'originLocationCode': origin,\n",
    "        'destinationLocationCode': destination,\n",
    "        'departureDate': date.today().isoformat(),\n",
    "        'adults': 1,\n",
    "        'currencyCode': 'USD',\n",
    "        'nonStop': 'true'  # Include only direct flights without stops\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the API request to retrieve flight offers for the current specific pair\n",
    "        flight_search = amadeus.shopping.flight_offers_search.get(**search_params)\n",
    "\n",
    "        # Process the response and append to the DataFrame\n",
    "        for offer in flight_search.data:\n",
    "            # Get the first segment from the first itinerary\n",
    "            segment = offer['itineraries'][0]['segments'][0]\n",
    "\n",
    "            # Extract relevant information\n",
    "            flight_number = segment['carrierCode'] + segment['number']\n",
    "            flight_date = segment['departure']['at']\n",
    "            airline_code = segment['carrierCode']\n",
    "\n",
    "            # Flight Create Orders to book the flight\n",
    "            booked_flight = amadeus.booking.flight_orders.post(offer, traveler).data\n",
    "\n",
    "            booking_id = booked_flight['id']\n",
    "\n",
    "            # Seat map to calculate sold seats\n",
    "            seats = amadeus.shopping.seatmaps.get(flightOrderId={booking_id}).data\n",
    "\n",
    "            # Initialize counters\n",
    "            total_seats = 0\n",
    "            available_seats = 0\n",
    "\n",
    "            # Loop through the response data to count seats and extract carrier code and flight number\n",
    "            for seatmap in seats:\n",
    "                for deck in seatmap['decks']:\n",
    "                    for seat in deck['seats']:\n",
    "                        total_seats += 1\n",
    "                        if 'seatAvailabilityStatus' in seat['travelerPricing'][0] and seat['travelerPricing'][0]['seatAvailabilityStatus'] == 'AVAILABLE':\n",
    "                            available_seats += 1\n",
    "\n",
    "            sold_seats = total_seats - available_seats\n",
    "\n",
    "            sold_seats = int(sold_seats)\n",
    "            price_total = float(offer['price']['total'])\n",
    "\n",
    "            Revenue = sold_seats * price_total\n",
    "\n",
    "            flight_data = flight_data.append({\n",
    "                'FlightNumber': flight_number,\n",
    "                'FlightDate': flight_date,\n",
    "                'Origin': origin,\n",
    "                'Destination': destination,\n",
    "                'AirlineCode': airline_code,\n",
    "                'Price': price_total,\n",
    "                'OrderID': booking_id,\n",
    "                'Total Seats': total_seats,\n",
    "                'Available Seats': available_seats,\n",
    "                'Total Revenue': Revenue\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        flight_data = flight_data.drop_duplicates()\n",
    "\n",
    "    except ResponseError as error:\n",
    "            print(f\"An error occurred while processing the specific pair: {origin} -> {destination}\")\n",
    "            print(f\"Error message: {error}\")\n",
    "            print(\"Traceback:\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the current date and time as YYYY-MM-DD_HH-MM-SS\n",
    "current_date_time = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# Set the file name using the current date and time\n",
    "file_name = f\"data_{current_date_time}.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "#flight_data.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {file_name}\")\n",
    "\n",
    "# Display the DataFrame with all the results\n",
    "print(flight_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric part of 'FlightNumber' in flights_data\n",
    "flight_data['Flight Number'] = flight_data['FlightNumber'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "df['Flight Number'] = df['Flight Number'].astype(int)\n",
    "\n",
    "# Merge dataframes based on common columns\n",
    "merged_data = flight_data.merge(df, how='left', left_on=['Origin', 'Destination', 'AirlineCode', 'Flight Number'], right_on=['Origin', 'Destination', 'Carrier Code', 'Flight Number'])\n",
    "\n",
    "# Clear 'Available Seats' column\n",
    "merged_data['Available Seats'] = 0\n",
    "\n",
    "# Clear 'Total Revenue' column\n",
    "merged_data['Total Revenue'] = 0\n",
    "\n",
    "# Fill 'Available Seats' with 'Total Bookable Seats' where available\n",
    "merged_data.loc[merged_data['Total Bookable Seats'].notnull(), 'Available Seats'] = merged_data['Total Bookable Seats']\n",
    "\n",
    "# Drop the additional columns\n",
    "merged_data.drop(['Carrier Code', 'Flight Number', 'Total Bookable Seats'], axis=1, inplace=True)\n",
    "\n",
    "# Calculate Revenue and remove rows with negative Revenue\n",
    "Revenue_indices_to_remove = []\n",
    "for index, row in merged_data.iterrows():\n",
    "    sold_seats = row['Total Seats'] - row['Available Seats']\n",
    "    sold_seats = int(sold_seats)\n",
    "    price_total = float(row['Price'])\n",
    "    Revenue = sold_seats * price_total\n",
    "    merged_data.at[index, 'Total Revenue'] = Revenue\n",
    "    if Revenue < 0:\n",
    "        Revenue_indices_to_remove.append(index)\n",
    "\n",
    "merged_data.drop(Revenue_indices_to_remove, inplace=True)\n",
    "\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_data = pd.read_csv('data_2023-08-09_18-00-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting datetime_column into date and time columns\n",
    "merged_data[['Date', 'Time']] = merged_data['FlightDate'].str.split('T', expand=True)\n",
    "\n",
    "# Converting date and time columns to datetime objects\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "merged_data['Time'] = pd.to_datetime(merged_data['Time']).dt.time\n",
    "\n",
    "# Dropping the original datetime_column\n",
    "merged_data.drop('FlightDate', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove first 2 letters from FlightNumber\n",
    "merged_data['FlightNumber'] = merged_data['FlightNumber'].apply(lambda x: x[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map airport codes to their corresponding names\n",
    "airport_mapping = {\n",
    "    'SDU': 'Rio',\n",
    "    'BSB': 'Brasilia',\n",
    "    'CGH': 'Congonhas',\n",
    "    'GRU': 'Guarulhos',\n",
    "    'SAL': 'Salvador',\n",
    "    'REC': 'Recife',\n",
    "    'CWB': 'Curitiba'\n",
    "}\n",
    "\n",
    "# Map origin and destination codes to names\n",
    "merged_data['Origin Name'] = merged_data['Origin'].map(airport_mapping)\n",
    "merged_data['Destination Name'] = merged_data['Destination'].map(airport_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new column order\n",
    "new_column_order = [\n",
    "    'AirlineCode', 'FlightNumber', 'Origin', 'Origin Name', 'Destination', 'Destination Name',\n",
    "    'Date', 'Time', 'Price', 'OrderID',\n",
    "    'Total Seats', 'Available Seats', 'Total Revenue'\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "merged_data = merged_data[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(merged_data['Destination Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flight_data.to_csv(file_name, index=False)\n",
    "\n",
    "#flight_data = flight_data.drop(index=flight_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "folder_path = 'C:\\\\Users\\\\Omar\\\\Desktop\\Masters Program\\\\Summer 2022\\\\Capstone project\\\\capstone project code'\n",
    "\n",
    "# Path to the existing mega consolidated CSV file\n",
    "existing_mega_csv_path = 'C:\\\\Users\\\\Omar\\\\Desktop\\\\Masters Program\\\\Summer 2022\\\\Capstone project\\\\capstone project code\\\\updated_mega_consolidated_data.csv'\n",
    "\n",
    "# Regular expression pattern to extract the date from the file name\n",
    "date_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv') and file != existing_mega_csv_path]\n",
    "\n",
    "# Read the existing mega consolidated CSV file\n",
    "existing_mega_data = pd.read_csv(existing_mega_csv_path)\n",
    "\n",
    "# Initialize an empty DataFrame to store consolidated data\n",
    "consolidated_data = pd.DataFrame()\n",
    "\n",
    "# Read the existing mega consolidated CSV file if it exists\n",
    "if os.path.exists(existing_mega_csv_path):\n",
    "    existing_mega_data = pd.read_csv(existing_mega_csv_path)\n",
    "    \n",
    "    # Convert the 'Date' column to datetime format if it exists\n",
    "    if 'Date' in existing_mega_data.columns:\n",
    "        existing_mega_data['Date'] = pd.to_datetime(existing_mega_data['Date'])\n",
    "        existing_dates = existing_mega_data['Date'].dt.date.tolist()\n",
    "    else:\n",
    "        existing_dates = []\n",
    "else:\n",
    "    existing_dates = []\n",
    "\n",
    "\n",
    "# Iterate through CSV files\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # Extract date from the file title using regular expression\n",
    "    match = re.search(date_pattern, csv_file)\n",
    "    if match:\n",
    "        file_date = match.group()\n",
    "        file_date = datetime.strptime(file_date, '%Y-%m-%d').date()\n",
    "        \n",
    "        # Check if the date already exists in the existing mega CSV\n",
    "        if file_date not in existing_dates:\n",
    "            # Read the CSV file\n",
    "            data = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Add data to the consolidated DataFrame\n",
    "            consolidated_data = pd.concat([consolidated_data, data], ignore_index=True)\n",
    "\n",
    "# Convert 'Date' to datetime\n",
    "consolidated_data['Date'] = pd.to_datetime(consolidated_data['Date'])\n",
    "\n",
    "# Append the new data to the existing mega CSV\n",
    "new_mega_data = pd.concat([existing_mega_data, consolidated_data], ignore_index=True)\n",
    "\n",
    "# Save the updated mega consolidated data to a CSV\n",
    "new_mega_data.to_csv('updated_mega_consolidated_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mega_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
